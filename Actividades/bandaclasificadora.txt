import pandas as pd
from sklearn.linear_model import LogisticRegression
df = pd.read_csv("tcs_dataset.csv")   
df.head()
df["label"].value_counts()
#normalización de RGB a r y g
S = df["red"] + df["green"] + df["blue"]

# Eliminandos filas raras donde S=0 (sin luz)
df = df[S > 0].copy()
S = df["red"] + df["green"] + df["blue"]
df["r"] = df["red"] / S
df["g"] = df["green"] / S
df[["red", "green", "blue", "r", "g", "label"]]
X = df[["r", "g"]].values
# y: 0 para Red, 1 para Green
y = (df["label"] == "Green").astype(int).values

print("Primeras X (r,g):")
print(X[:5])

print("\nPrimeras y (0=Red, 1=Green):")
print(y[:5])
clf = LogisticRegression()
clf.fit(X, y)
print("Modelo entrenado.")
y_pred = clf.predict(X)
accuracy = (y_pred == y).mean()

print("Etiquetas reales:   ", y.tolist())
print("Etiquetas predichas:", y_pred.tolist())
print("\nExactitud (accuracy):", accuracy)
# Extrayendo pesos
W0 = clf.coef_[0, 0]       # peso para r
W1 = clf.coef_[0, 1]       # peso para g
BIAS = clf.intercept_[0]   # término independiente

print("W0 =", W0)
print("W1 =", W1)
print("BIAS =", BIAS)

print("\nCódigo para pegar en Arduino:\n")
print(f"float W0   = {W0:.4f}f;")
print(f"float W1   = {W1:.4f}f;")
print(f"float BIAS = {BIAS:.4f}f;")